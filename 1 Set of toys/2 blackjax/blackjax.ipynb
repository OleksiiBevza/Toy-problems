{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c748d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code for generating and running toy problems with blackjax mala mcmc sampler\n",
    "\"\"\"\n",
    "\n",
    "##################################################################################\n",
    "# 1. PACKAGES\n",
    "##################################################################################\n",
    "\n",
    "# diagnostics\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import corner\n",
    "import logging\n",
    "logging.getLogger(\"matplotlib.font_manager\").setLevel(logging.ERROR)\n",
    "\n",
    "# blackjax \n",
    "import blackjax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# my classes\n",
    "from likelihood import *\n",
    "from gaussian_mixture import *\n",
    "\n",
    "\n",
    "SUPPORTED_EXPERIMENTS = [\"gaussian\"]\n",
    "##################################################################################\n",
    "# 2. ARGUMENTS\n",
    "##################################################################################\n",
    "### The argparse is used to store and process any user input we want to pass on\n",
    "parser = argparse.ArgumentParser(description=\"Run experiment with specified parameters.\")\n",
    "parser.add_argument(\n",
    "    \"--experiment-type\",\n",
    "    choices=[\"gaussian\", \"dualmoon\", \"rosenbrock\"],\n",
    "    required=True,\n",
    "    help=\"Which experiment to run.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-dims\",\n",
    "    type=int,\n",
    "    required=True,\n",
    "    help=\"Number of dimensions.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--outdir\",\n",
    "    type=str,\n",
    "    required=True,\n",
    "    help=\"The output directory, where things will be stored\"\n",
    ")\n",
    "\n",
    "# Everything below here are hyperparameters for the flowMC algorithms. \n",
    "parser.add_argument(\n",
    "    \"--mala-step-size\",\n",
    "    type=float,\n",
    "    default=1e-1,\n",
    "    help=\"Step size for the MALA proposal (local sampler).\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-chains\",\n",
    "    type=int,\n",
    "    default=20,\n",
    "    help=\"Number of Markov chains to process in parallel.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-steps\",\n",
    "    type=int,\n",
    "    default=5000,\n",
    "    help=\"Number of Markov chains to process in parallel.\"\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--show-initial-positions\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Show initial chain positions.\"\n",
    ")\n",
    "\n",
    "# Everything below here are hyperparameters for the Gaussian experiment. \n",
    "parser.add_argument(\n",
    "    \"--nr-of-samples\",\n",
    "    type=int,\n",
    "    default=10000,\n",
    "    help=\"Number of samples to be geerated\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--nr-of-components\",\n",
    "    type=int,\n",
    "    default=2,\n",
    "    help=\"Number of components to be geerated\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--width-mean\",\n",
    "    type=float,\n",
    "    default=10.0,\n",
    "    help=\"The width of mean\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--width-cov\",\n",
    "    type=float,\n",
    "    default=3.0,\n",
    "    help=\"The width of cov\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--weights-of-components\",\n",
    "    nargs=\"+\",          \n",
    "    type=float,\n",
    "    default=None,\n",
    "    help=\"Mixture weights (--weights-of-components 0.3 0.7). If omitted, uses equal weights.\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# 3. EXPERIMENT RUNNER\n",
    "##################################################################################\n",
    "class BlackjaxExperimentRunner:\n",
    "    \"\"\"\n",
    "    Base class storing everything shared between different run experiments\n",
    "    \"\"\"\n",
    "    def __init__(self, args):\n",
    "        # Process the argparse args into params:\n",
    "        self.params = vars(args)\n",
    "\n",
    "        # Automatically create a unique output directory: results_1, results_2, ...\n",
    "        base_results_dir = self.params[\"outdir\"]\n",
    "        unique_outdir = self.get_next_available_outdir(base_results_dir)\n",
    "        print(f\"Using output directory: {unique_outdir}\")\n",
    "        os.makedirs(unique_outdir, exist_ok=False)\n",
    "        self.params[\"outdir\"] = unique_outdir\n",
    "\n",
    "        # Check if experiment type is allowed/supported:\n",
    "        if self.params[\"experiment_type\"] not in SUPPORTED_EXPERIMENTS:\n",
    "            raise ValueError(\n",
    "                f\"Experiment type {self.params['experiment_type']} is not supported. \"\n",
    "                f\"Supported types are: {SUPPORTED_EXPERIMENTS}\"\n",
    "            )\n",
    "\n",
    "        # Show the parameters to the screen/log file\n",
    "        print(\"Passed parameters:\")\n",
    "        for key, value in self.params.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "\n",
    "\n",
    "        # Specify the desired target function based on the experiment type\n",
    "        # ... your outdir logic etc ...\n",
    "        if self.params[\"experiment_type\"] == \"gaussian\":\n",
    "            print(\"Setting the target function to a standard Gaussian distribution.\")\n",
    "            \n",
    "            # define parameters for mcmc sampler           \n",
    "            np.random.seed(900)\n",
    "\n",
    "            D = self.params[\"n_dims\"]\n",
    "            \n",
    "            true_samples, means, covariances, weights = GaussianMixtureGenerator.generate_gaussian_mixture(\n",
    "                n_dim=D,\n",
    "                n_gaussians=args.nr_of_components,\n",
    "                n_samples = args.nr_of_samples,\n",
    "                width_mean = args.width_mean,\n",
    "                width_cov = args.width_cov,\n",
    "                weights= args.weights_of_components,\n",
    "            ) \n",
    "\n",
    "            # Store true samples for diagnostics \n",
    "            self.true_samples = true_samples\n",
    "\n",
    "            # Convert to JAX arrays \n",
    "            mcmc_means   = jnp.stack(means, axis=0)         # (K, D)\n",
    "            mcmc_covs    = jnp.stack(covariances, axis=0)   # (K, D, D)\n",
    "            mcmc_weights = jnp.asarray(weights)             # (K,)\n",
    "\n",
    "            # Define Likelihood \n",
    "            self.likelihood = GaussianMixtureLikelihood(\n",
    "                means=mcmc_means,\n",
    "                covs=mcmc_covs,\n",
    "                weights=mcmc_weights,\n",
    "            )\n",
    "\n",
    "            self.target_fn = self.target_normal\n",
    "\n",
    "        elif self.params[\"experiment_type\"] == \"dualmoon\":\n",
    "            self.target_fn = self.target_dual_moon\n",
    "            print(f\"Setting the target function to a dual moon distribution.\")\n",
    "        elif self.params[\"experiment_type\"] == \"rosenbrock\":\n",
    "            self.target_fn = self.target_rosenbrock\n",
    "            print(f\"Setting the target function to a Rosenbrock distribution.\")\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    def get_next_available_outdir(self, base_dir: str, prefix: str = \"results\") -> str:\n",
    "        if not os.path.exists(base_dir):\n",
    "            os.makedirs(base_dir)\n",
    "\n",
    "        existing = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "        matches = [re.match(rf\"{prefix}_(\\d+)\", name) for name in existing]\n",
    "        numbers = [int(m.group(1)) for m in matches if m]\n",
    "        next_number = max(numbers, default=0) + 1\n",
    "        return os.path.join(base_dir, f\"{prefix}_{next_number}\")\n",
    "\n",
    "\n",
    "\n",
    "    def target_normal(self, x, data):\n",
    "        # x can be shape (D,) or (..., D); GaussianMixtureLikelihood.log_prob supports both\n",
    "        return self.likelihood.log_prob(x)\n",
    "\n",
    "\n",
    "\n",
    "    # cover all components \n",
    "    def init_chains_gmm_cover_all(self, key, n_chains, means, covs, cov_scale=1.0):\n",
    "        \"\"\"\n",
    "        means: (K, D)\n",
    "        covs:  (K, D, D)\n",
    "        returns: (n_chains, D)\n",
    "        \"\"\"\n",
    "        K, D = means.shape\n",
    "\n",
    "        # assign components so every component appears (if n_chains >= K)\n",
    "        if n_chains >= K:\n",
    "            reps = n_chains // K\n",
    "            rem  = n_chains % K\n",
    "            comp_ids = jnp.concatenate([\n",
    "                jnp.repeat(jnp.arange(K), reps),\n",
    "                jnp.arange(rem)\n",
    "            ])[:n_chains]\n",
    "            key, kperm = jax.random.split(key)\n",
    "            comp_ids = comp_ids[jax.random.permutation(kperm, n_chains)]\n",
    "        else:\n",
    "            # if fewer chains than components, can't cover all; pick first n_chains after shuffle\n",
    "            key, kperm = jax.random.split(key)\n",
    "            comp_ids = jax.random.permutation(kperm, K)[:n_chains]\n",
    "\n",
    "        # one key per chain\n",
    "        key, kdraw = jax.random.split(key)\n",
    "        keys = jax.random.split(kdraw, n_chains)\n",
    "\n",
    "        def draw_one(k, c):\n",
    "            return jax.random.multivariate_normal(k, means[c], covs[c] * cov_scale)\n",
    "\n",
    "        return jax.vmap(draw_one)(keys, comp_ids)\n",
    "\n",
    "\n",
    "\n",
    "    def nearest_mode_counts(self, x, means):\n",
    "        # x: (N,D), means: (K,D)\n",
    "        d2 = jnp.sum((x[:, None, :] - means[None, :, :])**2, axis=-1)  # (N,K)\n",
    "        ids = jnp.argmin(d2, axis=1)  # (N,)\n",
    "        K = means.shape[0]\n",
    "        return jnp.bincount(ids, length=K), ids\n",
    "\n",
    "\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # 3.1. SAMPLER \n",
    "    #-----------------------------------------------------------------------------\n",
    "    def run_experiment(self):\n",
    "        \"\"\"\n",
    "        Run the sampler for the chosen experiment\n",
    "        \"\"\"\n",
    "        dim = int(self.params[\"n_dims\"])\n",
    "        n_chains = int(self.params[\"n_chains\"])\n",
    "\n",
    "        rng_key = jax.random.PRNGKey(42)\n",
    "        # rng_key, subkey = jax.random.split(rng_key)\n",
    "        rng_key, key_init, key_bundle = jax.random.split(rng_key, 3)\n",
    "\n",
    "        # assign covering all components\n",
    "        if hasattr(self, \"likelihood\"):  \n",
    "            initial_position = self.init_chains_gmm_cover_all(\n",
    "            key_init,\n",
    "            self.params[\"n_chains\"],\n",
    "            self.likelihood.means,\n",
    "            self.likelihood.covs,\n",
    "            cov_scale=1.0,\n",
    "            )\n",
    "\n",
    "\n",
    "        #initial_position = jax.random.normal(subkey, shape=(n_chains, dim))\n",
    "\n",
    "        if self.params[\"show_initial_positions\"]:\n",
    "            print(\"Initial chain positions were:\")\n",
    "            print(initial_position)\n",
    "\n",
    "        data = {}\n",
    "\n",
    "        def logdensity_fn(x):\n",
    "            return self.target_fn(x, data)\n",
    "\n",
    "        step_size = float(self.params[\"mala_step_size\"])\n",
    "        num_steps = int(self.params[\"n_steps\"])\n",
    "\n",
    "        mala = blackjax.mala(logdensity_fn, step_size=step_size)\n",
    "        step = jax.jit(mala.step)\n",
    "\n",
    "        def run_one_chain(chain_key, init_pos):\n",
    "            state = mala.init(init_pos)\n",
    "\n",
    "            def one_step(state, key):\n",
    "                state, info = step(key, state)\n",
    "                return state, (state.position, info.acceptance_rate)\n",
    "\n",
    "            keys = jax.random.split(chain_key, num_steps)\n",
    "            _, (positions, acc_rates) = jax.lax.scan(one_step, state, keys)\n",
    "            return positions, acc_rates\n",
    "\n",
    "        chain_keys = jax.random.split(rng_key, n_chains)\n",
    "        positions, acc_rates = jax.vmap(run_one_chain)(chain_keys, initial_position)\n",
    "\n",
    "        self.chains = positions          # (n_chains, n_steps, dim)\n",
    "        self.acc_rates = acc_rates       # (n_chains, n_steps)\n",
    "\n",
    "        self.results = {\n",
    "            \"initial_position\": initial_position,\n",
    "            \"chains\": positions,        # (n_chains, n_steps, dim)\n",
    "            \"acc_rates\": acc_rates,     # (n_chains, n_steps)\n",
    "            \"params\": self.params,\n",
    "            }\n",
    "\n",
    "        print(\"Sampling complete!\")\n",
    "        print(\"Mean acceptance rate per chain:\", jnp.mean(acc_rates, axis=1))\n",
    "        print(\"Overall mean acceptance rate:\", jnp.mean(acc_rates))\n",
    "\n",
    "        return self.results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # 3.2. PLOT DIAGNOSTICS \n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    def get_true_and_mcmc_samples(self, discard=0, thin=1):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        true_np: (N_true, dim)\n",
    "        mcmc_np: (N_mcmc, dim)\n",
    "\n",
    "        Notes:\n",
    "        - This runner uses BlackJAX directly, so samples live in self.chains\n",
    "        with shape (n_chains, n_steps, dim).\n",
    "        - discard: number of initial steps per chain to drop (burn-in)\n",
    "        - thin: keep every `thin`-th sample\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"true_samples\") or self.true_samples is None:\n",
    "            raise ValueError(\"No true samples found. Ensure self.true_samples is set (gaussian experiment).\")\n",
    "\n",
    "        if not hasattr(self, \"chains\") or self.chains is None:\n",
    "            raise ValueError(\"No MCMC chains found. Run run_experiment() before extracting samples.\")\n",
    "\n",
    "        dim = int(self.params[\"n_dims\"])\n",
    "\n",
    "        true_np = np.asarray(self.true_samples).reshape(-1, dim)\n",
    "\n",
    "        chains = np.asarray(self.chains)  # (n_chains, n_steps, dim)\n",
    "        chains = chains[:, int(discard)::int(thin), :]\n",
    "        mcmc_np = chains.reshape(-1, dim)\n",
    "\n",
    "        return true_np, mcmc_np\n",
    "    \n",
    "\n",
    "\n",
    "    def plot_true_vs_mcmc_corner(self, seed=2046):\n",
    "        \"\"\"\n",
    "        Overlay corner plot:\n",
    "        - MCMC production samples (green)\n",
    "        - true samples (red)\n",
    "        Saves: true_vs_mcmc_corner_plot.pdf\n",
    "        \"\"\"\n",
    "        import os\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        import corner\n",
    "\n",
    "        # Get samples\n",
    "        true_np, mcmc_np = self.get_true_and_mcmc_samples()\n",
    "\n",
    "        dim = int(self.params[\"n_dims\"])\n",
    "        labels = [f\"x{i}\" for i in range(dim)]\n",
    "\n",
    "        outdir = self.params[\"outdir\"]\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "        # Plot MCMC first \n",
    "        fig = corner.corner(\n",
    "            mcmc_np,\n",
    "            color=\"green\",\n",
    "            hist_kwargs={\"color\": \"green\", \"density\": True},\n",
    "            show_titles=True,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "        # Overlay true samples \n",
    "        corner.corner(\n",
    "            true_np,\n",
    "            fig=fig,\n",
    "            color=\"red\",\n",
    "            hist_kwargs={\"color\": \"red\", \"density\": True},\n",
    "            show_titles=True,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "        # Legend\n",
    "        handles = [\n",
    "            plt.Line2D([], [], color=\"green\", label=\"blackjax\"),\n",
    "            plt.Line2D([], [], color=\"red\", label=\"True Normal\"),\n",
    "        ]\n",
    "        fig.legend(handles=handles, loc=\"upper right\")\n",
    "\n",
    "        save_name = os.path.join(outdir, \"true_vs_mcmc_corner_plot.pdf\")\n",
    "        fig.savefig(save_name, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "        print(f\"Saved overlay corner plot to {save_name}\")\n",
    "\n",
    "\n",
    "\n",
    "    def plot_acceptance_rate(self):\n",
    "        print(\"Plotting BlackJAX diagnostic curve (acceptance rate)...\")\n",
    "        if not hasattr(self, \"acc_rates\") or self.acc_rates is None:\n",
    "            raise ValueError(\"No acceptance-rate history found. Run run_experiment() first.\")\n",
    "\n",
    "        acc = np.asarray(self.acc_rates)  # (n_chains, n_steps)\n",
    "        mean_acc = acc.mean(axis=0)       # (n_steps,)\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(mean_acc)\n",
    "        plt.xlabel(\"MCMC Step\")\n",
    "        plt.ylabel(\"Mean acceptance rate (across chains)\")\n",
    "        plt.title(\"BlackJAX MALA Acceptance Rate\")\n",
    "\n",
    "        save_name = os.path.join(self.params[\"outdir\"], \"acceptance_rate_curve.pdf\")\n",
    "        print(f\"Saving diagnostic curve to {save_name}\")\n",
    "        plt.savefig(save_name, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        print(\"Acceptance rate curve plot saved.\")\n",
    "\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # 3.3. SAMPLE STATISTICS\n",
    "    #-----------------------------------------------------------------------------\n",
    "    def save_samples_json(self):\n",
    "        import os, json\n",
    "\n",
    "        # output directory \n",
    "        outdir = self.params[\"outdir\"]\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "        # get samples\n",
    "        true_np, mcmc_np = self.get_true_and_mcmc_samples()\n",
    "\n",
    "        # save MCMC\n",
    "        mcmc_path = os.path.join(outdir, \"mcmc_samples.json\")\n",
    "        with open(mcmc_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(mcmc_np.tolist(), f)\n",
    "        print(f\"MCMC samples saved to {mcmc_path}\")\n",
    "\n",
    "        # save TRUE\n",
    "        true_path = os.path.join(outdir, \"true_samples.json\")\n",
    "        with open(true_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(true_np.tolist(), f)\n",
    "        print(f\"True samples saved to {true_path}\")\n",
    "\n",
    "\n",
    "    def compute_and_save_sample_statistics(self):\n",
    "        \"\"\"\n",
    "        Computes and saves per-dimension statistics for:\n",
    "        - MCMC production samples\n",
    "        - true samples\n",
    "        Saves: sample_statistics.txt in self.params[\"outdir\"]\n",
    "        \"\"\"\n",
    "        import os\n",
    "        import numpy as np\n",
    "\n",
    "        # get samples\n",
    "        true_samples, mcmc_samples = self.get_true_and_mcmc_samples()\n",
    "\n",
    "        # MCMC stats\n",
    "        self.pm = mcmc_samples.mean(axis=0)\n",
    "        self.pv = mcmc_samples.var(axis=0)\n",
    "        self.ps = mcmc_samples.std(axis=0)\n",
    "\n",
    "        # True stats\n",
    "        self.qm = true_samples.mean(axis=0)\n",
    "        self.qv = true_samples.var(axis=0)\n",
    "        self.qs = true_samples.std(axis=0)\n",
    "\n",
    "        # store arrays \n",
    "        self.mcmc_samples = mcmc_samples\n",
    "        self.true_samples_np = true_samples\n",
    "\n",
    "        np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "        stats_str = (\n",
    "            \"pm (mean of MCMC samples):\\n\" + str(self.pm) +\n",
    "            \"\\n\\npv (variance of MCMC samples):\\n\" + str(self.pv) +\n",
    "            \"\\n\\nps (std dev of MCMC samples):\\n\" + str(self.ps) +\n",
    "            \"\\n\\nqm (mean of true samples):\\n\" + str(self.qm) +\n",
    "            \"\\n\\nqv (variance of true samples):\\n\" + str(self.qv) +\n",
    "            \"\\n\\nqs (std dev of true samples):\\n\" + str(self.qs) + \"\\n\"\n",
    "        )\n",
    "\n",
    "        outdir = self.params[\"outdir\"]\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "        stats_path = os.path.join(outdir, \"sample_statistics.txt\")\n",
    "        with open(stats_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(stats_str)\n",
    "\n",
    "        print(f\"Sample statistics saved to {stats_path}\")\n",
    "\n",
    "\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # 3.4. KL DIVERGENCE\n",
    "    #-----------------------------------------------------------------------------\n",
    "    import numpy as np, warnings, os\n",
    "    from typing import Tuple\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def gau_kl(pm: np.ndarray, pv: np.ndarray,\n",
    "               qm: np.ndarray, qv: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Kullback-Liebler divergence from Gaussian pm,pv to Gaussian qm,qv.\n",
    "        Also computes KL divergence from a single Gaussian pm,pv to a set\n",
    "         of Gaussians qm,qv.\n",
    "        Diagonal covariances are assumed.  Divergence is expressed in nats.\n",
    "        \"\"\"\n",
    "        if (len(qm.shape) == 2):\n",
    "            axis = 1\n",
    "        else:\n",
    "            axis = 0\n",
    "        # Determinants of diagonal covariances pv, qv\n",
    "        dpv = pv.prod()\n",
    "        dqv = qv.prod(axis)\n",
    "        # Inverse of diagonal covariance qv\n",
    "        iqv = 1. / qv\n",
    "        # Difference between means pm, qm\n",
    "        diff = qm - pm\n",
    "        return (0.5 * (\n",
    "            np.log(dqv / dpv)                 # log |\\Sigma_q| / |\\Sigma_p|\n",
    "            + (iqv * pv).sum(axis)            # + tr(\\Sigma_q^{-1} * \\Sigma_p)\n",
    "            + (diff * iqv * diff).sum(axis)   # + (\\mu_q-\\mu_p)^T\\Sigma_q^{-1}(\\mu_q-\\mu_p)\n",
    "            - len(pm)                         # - N\n",
    "        ))\n",
    "    \n",
    "\n",
    "    def kl_metrics(\n",
    "        self,\n",
    "        outdir: str | None = None,\n",
    "        filename: str = \"kl_metrics.txt\",\n",
    "    ) -> None:\n",
    "        import os\n",
    "        import numpy as np\n",
    "\n",
    "        # Define outdir\n",
    "        outdir = (\n",
    "            outdir\n",
    "            or (getattr(self, \"params\", {}) or {}).get(\"outdir\", None)\n",
    "            or getattr(self, \"outdir\", None)\n",
    "        )\n",
    "        if outdir is None:\n",
    "            raise ValueError(\"No output directory specified (pass outdir=... or set params['outdir']).\")\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "        # Get samples\n",
    "        true_np, mcmc_np = self.get_true_and_mcmc_samples() \n",
    "\n",
    "        # Parametric Gaussian stats (diagonal covariance assumed)\n",
    "        pm = mcmc_np.mean(axis=0)\n",
    "        pv = mcmc_np.var(axis=0)\n",
    "        qm = true_np.mean(axis=0)\n",
    "        qv = true_np.var(axis=0)\n",
    "\n",
    "        kl_val = self.gau_kl(pm, pv, qm, qv)  # scalar for 1D qm/qv\n",
    "\n",
    "        out_path = os.path.join(outdir, filename)\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            if np.isscalar(kl_val):\n",
    "                f.write(f\"Parametric KL (Gaussian): {float(kl_val):.8f}\\n\")\n",
    "            else:\n",
    "                kl_arr = np.asarray(kl_val).ravel()\n",
    "                f.write(\"Parametric KL (Gaussian):\\n\")\n",
    "                for i, v in enumerate(kl_arr):\n",
    "                    f.write(f\"  [{i}] {float(v):.8f}\\n\")\n",
    "\n",
    "        print(f\"KL metrics saved to {out_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b425ebce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using output directory: ./runs/gaussian_5d\\results_9\n",
      "Passed parameters:\n",
      "experiment_type: gaussian\n",
      "n_dims: 4\n",
      "outdir: ./runs/gaussian_5d\\results_9\n",
      "mala_step_size: 0.1\n",
      "n_chains: 10\n",
      "n_steps: 1000\n",
      "show_initial_positions: True\n",
      "nr_of_samples: 10000\n",
      "nr_of_components: 4\n",
      "width_mean: 10.0\n",
      "width_cov: 1.0\n",
      "weights_of_components: None\n",
      "Setting the target function to a standard Gaussian distribution.\n",
      "[-1.9527 -5.8704  7.5673 -5.8053]\n",
      "[-1.7255  1.3081  2.4974 -0.9036]\n",
      "[-1.6282 -0.0014  3.6579 -2.1062]\n",
      "[ 1.3373 -3.7496  6.6619  6.7686]\n",
      "Initial chain positions were:\n",
      "[[-5.5477 -0.8543  1.7817 -1.3673]\n",
      " [ 0.7932 -3.0263  8.1518  5.2368]\n",
      " [-0.3866 -7.0235  6.7723 -5.8014]\n",
      " [ 0.4926 -4.5503  6.4392  7.4438]\n",
      " [-4.2156 -2.3204  8.3174 -7.5876]\n",
      " [-1.7456 -1.1393  2.6385 -0.5381]\n",
      " [-3.264   1.1644  4.5745 -0.838 ]\n",
      " [-1.6756 -0.8838  3.7719 -0.9709]\n",
      " [-1.8493  1.8194  3.3371 -0.956 ]\n",
      " [-1.4142 -7.7683  7.4747 -5.1494]]\n",
      "Sampling complete!\n",
      "Mean acceptance rate per chain: [0.586  0.7683 0.3144 0.7795 0.3057 0.7322 0.6267 0.731  0.7588 0.3359]\n",
      "Overall mean acceptance rate: 0.5938381\n",
      "Saved overlay corner plot to ./runs/gaussian_5d\\results_9\\true_vs_mcmc_corner_plot.pdf\n",
      "Plotting BlackJAX diagnostic curve (acceptance rate)...\n",
      "Saving diagnostic curve to ./runs/gaussian_5d\\results_9\\acceptance_rate_curve.pdf\n",
      "Acceptance rate curve plot saved.\n",
      "MCMC samples saved to ./runs/gaussian_5d\\results_9\\mcmc_samples.json\n",
      "True samples saved to ./runs/gaussian_5d\\results_9\\true_samples.json\n",
      "Sample statistics saved to ./runs/gaussian_5d\\results_9\\sample_statistics.txt\n",
      "KL metrics saved to ./runs/gaussian_5d\\results_9\\kl_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.argv = [\n",
    "    ### The argparse is used to store and process any user input we want to pass on\n",
    "    \"notebook\",\n",
    "    \"--experiment-type\", \"gaussian\",\n",
    "    \"--outdir\", \"./runs/gaussian_5d\",\n",
    "\n",
    "    # Everything below here are hyperparameters for the flowMC algorithms.\n",
    "    \"--n-chains\", \"10\",\n",
    "    \"--n-steps\", \"1000\",                 \n",
    "    \"--mala-step-size\", \"1e-1\",\n",
    "    \"--show-initial-positions\",\n",
    "\n",
    "    # Everything below here are hyperparameters for the gaussians.\n",
    "    \"--n-dims\", \"4\",\n",
    "    \"--nr-of-samples\", \"10000\",\n",
    "    \"--nr-of-components\", \"4\",\n",
    "    \"--width-mean\", \"10.0\",\n",
    "    \"--width-cov\", \"1.0\",\n",
    "    #\"--weights-of-components\", \"0.4\", \"0.3\", \"0.3\"\n",
    "]\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Get the arguments passed over from the command line, and create the experiment runner\n",
    "    args = parser.parse_args()\n",
    "    runner = BlackjaxExperimentRunner(args)\n",
    "    runner.run_experiment()\n",
    "    runner.plot_true_vs_mcmc_corner()\n",
    "    runner.plot_acceptance_rate()\n",
    "    runner.save_samples_json()\n",
    "    runner.compute_and_save_sample_statistics()\n",
    "    runner.kl_metrics()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GRASP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
