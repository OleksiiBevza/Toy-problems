{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb693a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code for generating and running toy problems with flowMC\n",
    "\"\"\"\n",
    "##################################################################################\n",
    "# 1. PACKAGES\n",
    "##################################################################################\n",
    "\n",
    "# packages for diagnostics\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import corner\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"DejaVu Serif\", \"STIXGeneral\", \"Times New Roman\"],\n",
    "    \"mathtext.fontset\": \"stix\",\n",
    "})\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"matplotlib.font_manager\").setLevel(logging.ERROR)\n",
    "\n",
    "# packages for sampler\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.special import logsumexp\n",
    "from typing import Any\n",
    "\n",
    "from flowMC.resource.local_kernel.Gaussian_random_walk import GaussianRandomWalk\n",
    "from flowMC.resource.buffers import Buffer\n",
    "from flowMC.resource.logPDF import LogPDF\n",
    "from flowMC.strategy.optimization import AdamOptimization\n",
    "from flowMC.strategy.take_steps import TakeSerialSteps\n",
    "from flowMC.resource.nf_model.realNVP import RealNVP\n",
    "from flowMC.resource.nf_model.rqSpline import MaskedCouplingRQSpline\n",
    "from flowMC.resource_strategy_bundle.RQSpline_MALA import RQSpline_MALA_Bundle\n",
    "from flowMC.Sampler import Sampler\n",
    "\n",
    "import arviz as az\n",
    "import xarray as xr\n",
    "import re\n",
    "\n",
    "# packages for Likelihood\n",
    "from jax.scipy.linalg import solve_triangular\n",
    "from jax.scipy.special import logsumexp\n",
    "from typing import Mapping, Sequence, Union\n",
    "\n",
    "# packages for gaussian mixture generator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import corner\n",
    "\n",
    "\n",
    "from likelihood import *\n",
    "from gaussian_mixture import *\n",
    "\n",
    "\n",
    "SUPPORTED_EXPERIMENTS = [\"gaussian\", \"dualmoon\", \"rosenbrock\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# 2. ARGUMENTS\n",
    "##################################################################################\n",
    "### The argparse is used to store and process any user input we want to pass on\n",
    "parser = argparse.ArgumentParser(description=\"Run experiment with specified parameters.\")\n",
    "parser.add_argument(\n",
    "    \"--experiment-type\",\n",
    "    choices=[\"gaussian\", \"dualmoon\", \"rosenbrock\"],\n",
    "    required=True,\n",
    "    help=\"Which experiment to run.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-dims\",\n",
    "    type=int,\n",
    "    required=True,\n",
    "    help=\"Number of dimensions.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--outdir\",\n",
    "    type=str,\n",
    "    required=True,\n",
    "    help=\"The output directory, where things will be stored\"\n",
    ")\n",
    "\n",
    "# Everything below here are hyperparameters for the flowMC algorithms. \n",
    "parser.add_argument(\n",
    "    \"--n-local-steps\",\n",
    "    type=int,\n",
    "    default=20,\n",
    "    help=\"Number of local steps.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-global-steps\",\n",
    "    type=int,\n",
    "    default=50,\n",
    "    help=\"Number of global steps.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-training-loops\",\n",
    "    type=int,\n",
    "    default=20,\n",
    "    help=\"Number of training loops.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--mala-step-size\",\n",
    "    type=float,\n",
    "    default=1e-1,\n",
    "    help=\"Step size for the MALA proposal (local sampler).\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-production-loops\",\n",
    "    type=int,\n",
    "    default=20,\n",
    "    help=\"Number of production loops.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-epochs\",\n",
    "    type=int,\n",
    "    default=5,\n",
    "    help=\"Number of epochs to train the NF.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-chains\",\n",
    "    type=int,\n",
    "    default=20,\n",
    "    help=\"Number of Markov chains to process in parallel.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--rq-spline-hidden-units\",\n",
    "    type=int,\n",
    "    default=32,\n",
    "    help=\"Spline number of hidden units (used in the NF).\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--rq-spline-n-bins\",\n",
    "    type=int,\n",
    "    default=8,\n",
    "    help=\"Number of spline bins used in the NF.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--rq-spline-n-layers\",\n",
    "    type=int,\n",
    "    default=4,\n",
    "    help=\"Number of spline layers used in the NF.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--learning-rate\",\n",
    "    type=float,\n",
    "    default=1e-3,\n",
    "    help=\"Learning rate for the NF training.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--batch-size\",\n",
    "    type=int,\n",
    "    default=10000,\n",
    "    help=\"Batch size for NF training.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-max-examples\",\n",
    "    type=int,\n",
    "    default=10000,\n",
    "    help=\"Maximum number of examples for NF.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--show-initial-positions\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Show initial chain positions.\"\n",
    ")\n",
    "\n",
    "# Everything below here are hyperparameters for the Gaussian experiment. \n",
    "parser.add_argument(\n",
    "    \"--nr-of-samples\",\n",
    "    type=int,\n",
    "    default=10000,\n",
    "    help=\"Number of samples to be geerated\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--nr-of-components\",\n",
    "    type=int,\n",
    "    default=2,\n",
    "    help=\"Number of components to be geerated\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--width-mean\",\n",
    "    type=float,\n",
    "    default=10.0,\n",
    "    help=\"The width of mean\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--width-cov\",\n",
    "    type=float,\n",
    "    default=2.0,\n",
    "    help=\"The width of cov\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--weights-of-components\",\n",
    "    nargs=\"+\",          \n",
    "    type=float,\n",
    "    default=None,\n",
    "    help=\"Mixture weights (--weights-of-components 0.3 0.7). If omitted, uses equal weights.\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# 3. EXPERIMENT RUNNER\n",
    "##################################################################################\n",
    "class FlowMCExperimentRunner:\n",
    "    \"\"\"\n",
    "    Base class storing everything shared between different run experiments\n",
    "    \"\"\"\n",
    "    def __init__(self, args):\n",
    "        # Process the argparse args into params:\n",
    "        self.params = vars(args)\n",
    "\n",
    "        # Automatically create a unique output directory: results_1, results_2, ...\n",
    "        base_results_dir = self.params[\"outdir\"]\n",
    "        unique_outdir = self.get_next_available_outdir(base_results_dir)\n",
    "        print(f\"Using output directory: {unique_outdir}\")\n",
    "        os.makedirs(unique_outdir)\n",
    "        self.params[\"outdir\"] = unique_outdir\n",
    "\n",
    "        # Check if experiment type is allowed/supported:\n",
    "        if not self.params[\"experiment_type\"] in SUPPORTED_EXPERIMENTS:\n",
    "            raise ValueError(f\"Experiment type {self.params['experiment_type']} is not supported. Supported types are: {SUPPORTED_EXPERIMENTS}\")\n",
    "\n",
    "        # Show the parameters to the screen/log file\n",
    "        print(f\"Passed parameters:\")\n",
    "        for key, value in self.params.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "\n",
    "        # Specify the desired target function based on the experiment type\n",
    "        # ... your outdir logic etc ...\n",
    "\n",
    "        if self.params[\"experiment_type\"] == \"gaussian\":\n",
    "            print(\"Setting the target function to a Gaussian mixture distribution.\")\n",
    "\n",
    "            # define parameters for mcmc sampler\n",
    "            np.random.seed(900)\n",
    "\n",
    "            D = self.params[\"n_dims\"]\n",
    "            \n",
    "            true_samples, means, covariances, weights = GaussianMixtureGenerator.generate_gaussian_mixture(\n",
    "                n_dim=D,\n",
    "                n_gaussians=args.nr_of_components,\n",
    "                n_samples = args.nr_of_samples,\n",
    "                width_mean = args.width_mean,\n",
    "                width_cov = args.width_cov,\n",
    "                weights= args.weights_of_components,\n",
    "            ) \n",
    "\n",
    "            # Store true samples for diagnostics\n",
    "            self.true_samples = true_samples\n",
    "\n",
    "            # Convert to JAX arrays \n",
    "            mcmc_means   = jnp.stack(means, axis=0)         # (K, D)\n",
    "            mcmc_covs    = jnp.stack(covariances, axis=0)   # (K, D, D)\n",
    "            mcmc_weights = jnp.asarray(weights)             # (K,)\n",
    "\n",
    "            # Likelihood that will be used as sampler target \n",
    "            self.likelihood = GaussianMixtureLikelihood(\n",
    "                means=mcmc_means,\n",
    "                covs=mcmc_covs,\n",
    "                weights=mcmc_weights,\n",
    "            )\n",
    "\n",
    "            self.target_fn = self.target_normal\n",
    "\n",
    "        elif self.params[\"experiment_type\"] == \"dualmoon\":\n",
    "            self.target_fn = self.target_dual_moon\n",
    "            print(f\"Setting the target function to a dual moon distribution.\")\n",
    "        elif self.params[\"experiment_type\"] == \"rosenbrock\":\n",
    "            self.target_fn = self.target_rosenbrock\n",
    "            print(f\"Setting the target function to a Rosenbrock distribution.\")\n",
    "\n",
    "\n",
    "\n",
    "    def get_next_available_outdir(self, base_dir: str, prefix: str = \"results\") -> str:\n",
    "        if not os.path.exists(base_dir):\n",
    "            os.makedirs(base_dir)\n",
    "\n",
    "        existing = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "        matches = [re.match(rf\"{prefix}_(\\d+)\", name) for name in existing]\n",
    "        numbers = [int(m.group(1)) for m in matches if m]\n",
    "        next_number = max(numbers, default=0) + 1\n",
    "        return os.path.join(base_dir, f\"{prefix}_{next_number}\")\n",
    "\n",
    "\n",
    "\n",
    "    def target_normal(self, x, data):\n",
    "        # x can be shape (D,) or (..., D); GaussianMixtureLikelihood.log_prob supports both\n",
    "        return self.likelihood.log_prob(x)\n",
    "    \n",
    "\n",
    "    \n",
    "    # cover all components \n",
    "    def init_chains_gmm_cover_all(self, key, n_chains, means, covs, cov_scale=1.0):\n",
    "        \"\"\"\n",
    "        means: (K, D)\n",
    "        covs:  (K, D, D)\n",
    "        returns: (n_chains, D)\n",
    "        \"\"\"\n",
    "        K, D = means.shape\n",
    "\n",
    "        # assign components so every component appears (if n_chains >= K)\n",
    "        if n_chains >= K:\n",
    "            reps = n_chains // K\n",
    "            rem  = n_chains % K\n",
    "            comp_ids = jnp.concatenate([\n",
    "                jnp.repeat(jnp.arange(K), reps),\n",
    "                jnp.arange(rem)\n",
    "            ])[:n_chains]\n",
    "            key, kperm = jax.random.split(key)\n",
    "            comp_ids = comp_ids[jax.random.permutation(kperm, n_chains)]\n",
    "        else:\n",
    "            # if fewer chains than components: can't cover all and pick first n_chains after shuffle\n",
    "            key, kperm = jax.random.split(key)\n",
    "            comp_ids = jax.random.permutation(kperm, K)[:n_chains]\n",
    "\n",
    "        # one key per chain\n",
    "        key, kdraw = jax.random.split(key)\n",
    "        keys = jax.random.split(kdraw, n_chains)\n",
    "\n",
    "        def draw_one(k, c):\n",
    "            return jax.random.multivariate_normal(k, means[c], covs[c] * cov_scale)\n",
    "\n",
    "        return jax.vmap(draw_one)(keys, comp_ids)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def nearest_mode_counts(self, x, means):\n",
    "        # x: (N,D), means: (K,D)\n",
    "        d2 = jnp.sum((x[:, None, :] - means[None, :, :])**2, axis=-1)  # (N,K)\n",
    "        ids = jnp.argmin(d2, axis=1)  # (N,)\n",
    "        K = means.shape[0]\n",
    "        return jnp.bincount(ids, length=K), ids\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # 3.1. SAMPLER \n",
    "    #-----------------------------------------------------------------------------\n",
    "    def run_experiment(self):\n",
    "        \"\"\"\n",
    "        Run the sampler for the chosen experiment\n",
    "        \"\"\"\n",
    "        dim = self.params[\"n_dims\"]\n",
    "        rng_key = jax.random.PRNGKey(42)\n",
    "        rng_key, subkey = jax.random.split(rng_key)\n",
    "\n",
    "        rng_key = jax.random.PRNGKey(42)\n",
    "        rng_key, key_init, key_bundle = jax.random.split(rng_key, 3)\n",
    "\n",
    "        # initializing depends on whether target is multivariate normal\n",
    "        if hasattr(self, \"likelihood\"):  # GMM case\n",
    "            initial_position = self.init_chains_gmm_cover_all(\n",
    "            key_init,\n",
    "            self.params[\"n_chains\"],\n",
    "            self.likelihood.means,\n",
    "            self.likelihood.covs,\n",
    "            cov_scale=1.0,\n",
    "            )\n",
    "        #else:\n",
    "            #initial_position = jax.random.normal(key_init, (self.params[\"n_chains\"], dim))\n",
    "\n",
    "        if self.params[\"show_initial_positions\"]:\n",
    "            print(\"Initial chain positions were:\")\n",
    "            print(initial_position)\n",
    "\n",
    "\n",
    "        # How many chains start nearest each Gaussian mixture component\n",
    "        if hasattr(self, \"likelihood\") and hasattr(self.likelihood, \"means\"):\n",
    "            counts, _ = self.nearest_mode_counts(initial_position, self.likelihood.means)\n",
    "            print(\"Init chains per component:\", np.asarray(counts))\n",
    "\n",
    "        # TODO: check if OK like this\n",
    "        # data = {\"data\": jnp.arange(dim).astype(jnp.float32)}\n",
    "        data = {} # this is unused in our targets and therefore not important\n",
    "\n",
    "        # Putting hyperparameters into flowMC sampler\n",
    "        bundle = RQSpline_MALA_Bundle(\n",
    "            subkey,\n",
    "            self.params[\"n_chains\"],\n",
    "            dim,\n",
    "            self.target_fn,\n",
    "            self.params[\"n_local_steps\"],\n",
    "            self.params[\"n_global_steps\"],\n",
    "            self.params[\"n_training_loops\"],\n",
    "            self.params[\"n_production_loops\"],\n",
    "            self.params[\"n_epochs\"],\n",
    "            mala_step_size=self.params[\"mala_step_size\"],\n",
    "            rq_spline_hidden_units=[self.params[\"rq_spline_hidden_units\"], self.params[\"rq_spline_hidden_units\"]],\n",
    "            rq_spline_n_bins=self.params[\"rq_spline_n_bins\"],\n",
    "            rq_spline_n_layers=self.params[\"rq_spline_n_layers\"],\n",
    "            learning_rate=self.params[\"learning_rate\"],\n",
    "            batch_size=self.params[\"batch_size\"],\n",
    "            n_max_examples=self.params[\"n_max_examples\"],\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # Defining the Sampler\n",
    "        self.sampler = Sampler(\n",
    "            dim,\n",
    "            self.params[\"n_chains\"],\n",
    "            rng_key,\n",
    "            resource_strategy_bundles=bundle,\n",
    "        )\n",
    "\n",
    "        # Starting sampling:\n",
    "        print(f\"Starting the sampling now . . .\")\n",
    "        self.sampler.sample(initial_position, data)\n",
    "        print(f\"Sampling complete!\")\n",
    "\n",
    "        return self.sampler \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # 3.2. PLOT DIAGNOSTICS \n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    def get_true_and_mcmc_samples(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        true_np: (N_true, dim)\n",
    "        mcmc_np: (N_mcmc, dim)\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"true_samples\") or self.true_samples is None:\n",
    "            raise ValueError(\"No true samples found. Ensure self.true_samples is set (gaussian experiment).\")\n",
    "\n",
    "        if not hasattr(self, \"sampler\") or self.sampler is None:\n",
    "            raise ValueError(\"No sampler found. Run the sampler before extracting MCMC samples.\")\n",
    "\n",
    "        dim = int(self.params[\"n_dims\"])\n",
    "\n",
    "        true_np = np.asarray(self.true_samples).reshape(-1, dim)\n",
    "\n",
    "        chains = np.asarray(self.sampler.resources[\"positions_production\"].data)\n",
    "        mcmc_np = chains.reshape(-1, dim)\n",
    "\n",
    "        return true_np, mcmc_np\n",
    "\n",
    "\n",
    "\n",
    "    def plot_true_vs_mcmc_corner(self, seed=2046):\n",
    "        \"\"\"\n",
    "        Overlay corner plot:\n",
    "        - MCMC production samples (in blue)\n",
    "        - true samples (in red)\n",
    "        Saves: true_vs_mcmc_corner_plot.pdf\n",
    "        \"\"\"\n",
    "        # Get samples (both are (N, dim))\n",
    "        true_np, mcmc_np = self.get_true_and_mcmc_samples()\n",
    "\n",
    "        dim = int(self.params[\"n_dims\"])\n",
    "        labels = [f\"x{i}\" for i in range(dim)]\n",
    "\n",
    "        outdir = self.params[\"outdir\"]\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "        # Plot MCMC first (in blue)\n",
    "        fig = corner.corner(\n",
    "            mcmc_np,\n",
    "            color=\"blue\",\n",
    "            hist_kwargs={\"color\": \"blue\", \"density\": True},\n",
    "            show_titles=True,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "        # Overlay true samples (in red)\n",
    "        corner.corner(\n",
    "            true_np,\n",
    "            fig=fig,\n",
    "            color=\"red\",\n",
    "            hist_kwargs={\"color\": \"red\", \"density\": True},\n",
    "            show_titles=True,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "        # Legend\n",
    "        handles = [\n",
    "            plt.Line2D([], [], color=\"blue\", label=\"MCMC\"),\n",
    "            plt.Line2D([], [], color=\"red\", label=\"True Normal\"),\n",
    "        ]\n",
    "        fig.legend(handles=handles, loc=\"upper right\")\n",
    "\n",
    "        save_name = os.path.join(outdir, \"true_vs_mcmc_corner_plot.pdf\")\n",
    "        fig.savefig(save_name, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "        print(f\"Saved overlay corner plot to {save_name}\")\n",
    "\n",
    "\n",
    "\n",
    "    def plot_loss_curve(self):\n",
    "        \"\"\"\n",
    "        Plot the loss curve from the training of the normalizing flow.\n",
    "        \"\"\"\n",
    "        print(\"Plotting loss curve...\")\n",
    "        loss_data = self.sampler.resources[\"loss_buffer\"].data\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(loss_data.reshape(-1))\n",
    "        plt.xlabel(\"Training Step\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training Loss Curve\")\n",
    "        save_name = os.path.join(self.params[\"outdir\"], 'training_loss_curve.pdf')\n",
    "        print(f\"Saving loss curve to {save_name}\")\n",
    "        plt.savefig(save_name, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(\"Loss curve plot saved.\") \n",
    "\n",
    "\n",
    "\n",
    "    def plot_diagnostics(self):\n",
    "        \"\"\"\n",
    "        Make a diagnosis plot.\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"Making diagnosis plot . . .\")\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "        local_accs = self.sampler.resources[\"local_accs_production\"].data\n",
    "        global_accs = self.sampler.resources[\"global_accs_production\"].data\n",
    "        log_prob = self.sampler.resources[\"log_prob_production\"].data\n",
    "\n",
    "        mean_local_accs = np.mean(local_accs, axis=0)\n",
    "        mean_global_accs = np.mean(global_accs, axis=0)\n",
    "\n",
    "        axes[0].plot(mean_local_accs)\n",
    "        axes[0].set_title(f\"Local Acceptance Rate\")\n",
    "\n",
    "        axes[1].plot(mean_global_accs)\n",
    "        axes[1].set_title(f\"Global Acceptance Rate\")\n",
    "\n",
    "        axes[2].plot(log_prob[::5, ::20].T, lw=1, alpha=0.5)\n",
    "        axes[2].set_title(f\"Log Probability\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        save_name = os.path.join(self.params[\"outdir\"], 'acceptance_and_logprob.pdf')\n",
    "        print(f\"Saving diagnosis plots to {save_name}\")\n",
    "        plt.savefig(save_name, bbox_inches = \"tight\") \n",
    "        plt.close(fig)\n",
    "\n",
    "        print(f\"Making diagnosis plot . . . DONE!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # 3.3. SAMPLE STATISTICS\n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    def save_samples_json(self):\n",
    "        import os, json\n",
    "\n",
    "        # output directory \n",
    "        outdir = self.params[\"outdir\"]\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "        # get samples once\n",
    "        true_np, mcmc_np = self.get_true_and_mcmc_samples()\n",
    "\n",
    "        # save MCMC\n",
    "        mcmc_path = os.path.join(outdir, \"mcmc_samples.json\")\n",
    "        with open(mcmc_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(mcmc_np.tolist(), f)\n",
    "        print(f\"MCMC samples saved to {mcmc_path}\")\n",
    "\n",
    "        # save TRUE\n",
    "        true_path = os.path.join(outdir, \"true_samples.json\")\n",
    "        with open(true_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(true_np.tolist(), f)\n",
    "        print(f\"True samples saved to {true_path}\")\n",
    "\n",
    "\n",
    "\n",
    "    def compute_and_save_sample_statistics(self):\n",
    "        \"\"\"\n",
    "        Computes and saves per-dimension statistics for:\n",
    "        - MCMC production samples\n",
    "        - true samples\n",
    "        Saves: sample_statistics.txt in self.params[\"outdir\"]\n",
    "        \"\"\"\n",
    "\n",
    "        # get samples \n",
    "        true_samples, mcmc_samples = self.get_true_and_mcmc_samples()\n",
    "\n",
    "        # MCMC stats\n",
    "        self.pm = mcmc_samples.mean(axis=0)\n",
    "        self.pv = mcmc_samples.var(axis=0)\n",
    "        self.ps = mcmc_samples.std(axis=0)\n",
    "\n",
    "        # True stats\n",
    "        self.qm = true_samples.mean(axis=0)\n",
    "        self.qv = true_samples.var(axis=0)\n",
    "        self.qs = true_samples.std(axis=0)\n",
    "\n",
    "        # store arrays \n",
    "        self.mcmc_samples = mcmc_samples\n",
    "        self.true_samples_np = true_samples\n",
    "\n",
    "        np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "        stats_str = (\n",
    "            \"pm (mean of MCMC samples):\\n\" + str(self.pm) +\n",
    "            \"\\n\\npv (variance of MCMC samples):\\n\" + str(self.pv) +\n",
    "            \"\\n\\nps (std dev of MCMC samples):\\n\" + str(self.ps) +\n",
    "            \"\\n\\nqm (mean of true samples):\\n\" + str(self.qm) +\n",
    "            \"\\n\\nqv (variance of true samples):\\n\" + str(self.qv) +\n",
    "            \"\\n\\nqs (std dev of true samples):\\n\" + str(self.qs) + \"\\n\"\n",
    "        )\n",
    "\n",
    "        outdir = self.params[\"outdir\"]\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "        stats_path = os.path.join(outdir, \"sample_statistics.txt\")\n",
    "        with open(stats_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(stats_str)\n",
    "\n",
    "        print(f\"Sample statistics saved to {stats_path}\")\n",
    "    \n",
    "\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # 3.4. KL DIVERGENCE\n",
    "    #-----------------------------------------------------------------------------\n",
    "    import numpy as np, warnings, os\n",
    "    from typing import Tuple\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def gau_kl(pm: np.ndarray, pv: np.ndarray,\n",
    "               qm: np.ndarray, qv: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Kullback-Liebler divergence from Gaussian pm,pv to Gaussian qm,qv.\n",
    "        Also computes KL divergence from a single Gaussian pm,pv to a set\n",
    "         of Gaussians qm,qv.\n",
    "        Diagonal covariances are assumed.  Divergence is expressed in nats.\n",
    "        \"\"\"\n",
    "        if (len(qm.shape) == 2):\n",
    "            axis = 1\n",
    "        else:\n",
    "            axis = 0\n",
    "        # Determinants of diagonal covariances pv, qv\n",
    "        dpv = pv.prod()\n",
    "        dqv = qv.prod(axis)\n",
    "        # Inverse of diagonal covariance qv\n",
    "        iqv = 1. / qv\n",
    "        # Difference between means pm, qm\n",
    "        diff = qm - pm\n",
    "        return (0.5 * (\n",
    "            np.log(dqv / dpv)                 # log |\\Sigma_q| / |\\Sigma_p|\n",
    "            + (iqv * pv).sum(axis)            # + tr(\\Sigma_q^{-1} * \\Sigma_p)\n",
    "            + (diff * iqv * diff).sum(axis)   # + (\\mu_q-\\mu_p)^T\\Sigma_q^{-1}(\\mu_q-\\mu_p)\n",
    "            - len(pm)                         # - N\n",
    "        ))\n",
    "    \n",
    "\n",
    "    def kl_metrics(\n",
    "        self,\n",
    "        outdir: str | None = None,\n",
    "        filename: str = \"kl_metrics.txt\",\n",
    "    ) -> None:\n",
    "        \n",
    "        outdir = (\n",
    "            outdir\n",
    "            or (getattr(self, \"params\", {}) or {}).get(\"outdir\", None)\n",
    "            or getattr(self, \"outdir\", None)\n",
    "        )\n",
    "        if outdir is None:\n",
    "            raise ValueError(\"No output directory specified (pass outdir=... or set params['outdir']).\")\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "        # Get samples\n",
    "        true_np, mcmc_np = self.get_true_and_mcmc_samples()  # both (N, dim)\n",
    "\n",
    "        # Parametric Gaussian stats (diagonal covariance assumed)\n",
    "        pm = mcmc_np.mean(axis=0)\n",
    "        pv = mcmc_np.var(axis=0)\n",
    "        qm = true_np.mean(axis=0)\n",
    "        qv = true_np.var(axis=0)\n",
    "\n",
    "        kl_val = self.gau_kl(pm, pv, qm, qv)  # scalar for 1D qm/qv\n",
    "\n",
    "        out_path = os.path.join(outdir, filename)\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            if np.isscalar(kl_val):\n",
    "                f.write(f\"Parametric KL (Gaussian): {float(kl_val):.8f}\\n\")\n",
    "            else:\n",
    "                kl_arr = np.asarray(kl_val).ravel()\n",
    "                f.write(\"Parametric KL (Gaussian):\\n\")\n",
    "                for i, v in enumerate(kl_arr):\n",
    "                    f.write(f\"  [{i}] {float(v):.8f}\\n\")\n",
    "\n",
    "        print(f\"KL metrics saved to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507eb522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using output directory: ./runs/gaussian_5d\\results_14\n",
      "Passed parameters:\n",
      "experiment_type: gaussian\n",
      "n_dims: 4\n",
      "outdir: ./runs/gaussian_5d\\results_14\n",
      "n_local_steps: 40\n",
      "n_global_steps: 40\n",
      "n_training_loops: 20\n",
      "mala_step_size: 0.1\n",
      "n_production_loops: 20\n",
      "n_epochs: 10\n",
      "n_chains: 40\n",
      "rq_spline_hidden_units: 32\n",
      "rq_spline_n_bins: 8\n",
      "rq_spline_n_layers: 4\n",
      "learning_rate: 0.001\n",
      "batch_size: 5000\n",
      "n_max_examples: 10000\n",
      "show_initial_positions: True\n",
      "nr_of_samples: 10000\n",
      "nr_of_components: 4\n",
      "width_mean: 10.0\n",
      "width_cov: 1.0\n",
      "weights_of_components: None\n",
      "Setting the target function to a Gaussian mixture distribution.\n",
      "[-1.9527 -5.8704  7.5673 -5.8053]\n",
      "[-1.7255  1.3081  2.4974 -0.9036]\n",
      "[-1.6282 -0.0014  3.6579 -2.1062]\n",
      "[ 1.3373 -3.7496  6.6619  6.7686]\n",
      "Initial chain positions were:\n",
      "[[-1.7681 -3.2416  5.5455  7.0215]\n",
      " [ 0.7932 -3.0263  8.1518  5.2368]\n",
      " [-0.6173 -0.8412  2.9095 -2.8321]\n",
      " [-3.1887 -6.303   7.2092 -4.4476]\n",
      " [-3.0889  3.3572  3.5035 -4.253 ]\n",
      " [-1.8785  0.095   0.1371 -1.0926]\n",
      " [-3.264   1.1644  4.5745 -0.838 ]\n",
      " [-1.7872  0.4074  1.711  -0.9854]\n",
      " [ 1.2367 -3.1782  6.8698  5.7786]\n",
      " [-1.2725 -0.3154  1.5893 -1.6405]\n",
      " [-4.04   -5.9266  9.1059 -5.1107]\n",
      " [-1.328  -1.4445  4.5038  0.2754]\n",
      " [-1.7423 -1.7912  5.1518 -2.0034]\n",
      " [-2.5784 -5.6703  7.589  -5.5422]\n",
      " [ 0.0591 -3.9433  9.3456  5.606 ]\n",
      " [-3.5074  2.17    2.58   -0.8718]\n",
      " [-2.181  -2.3663  4.7147 -1.7988]\n",
      " [-0.1406 -3.7838  4.2987  8.9194]\n",
      " [-2.4277 -0.6665  4.2271 -2.3478]\n",
      " [-0.0451  0.5381  1.7197 -1.6762]\n",
      " [ 2.9335 -4.7324  5.8841  8.2431]\n",
      " [-0.7965  1.1694  3.9875 -1.0619]\n",
      " [ 1.0773  4.8085  3.0141 -0.4587]\n",
      " [-0.5865 -7.4779  5.7974 -3.5663]\n",
      " [ 0.3318 -1.7074  4.5402  7.8473]\n",
      " [-0.6737 -2.4504  4.5423 -3.0555]\n",
      " [ 2.6293 -2.9116  5.9891  6.8314]\n",
      " [ 4.4392 -5.881   9.5342  4.659 ]\n",
      " [-2.4728 -5.9735  7.2951 -5.0762]\n",
      " [-3.0285 -3.8926  6.887  -6.197 ]\n",
      " [-0.1127  1.2355  1.097  -0.9747]\n",
      " [ 2.7248 -2.7349  6.8477  6.2938]\n",
      " [-0.3014  0.8986  1.1865 -0.8181]\n",
      " [ 2.134  -6.3819  7.6833 -8.1146]\n",
      " [-0.5421 -3.4303  7.9537 -9.2308]\n",
      " [-3.0223  1.2839  4.6808 -0.5799]\n",
      " [-2.9853  0.0958  3.1112 -1.0438]\n",
      " [-0.3975 -5.5152  7.6217 -6.9035]\n",
      " [ 0.9516 -8.17    6.9464 -6.0625]\n",
      " [-0.5854 -0.5441  3.1351 -0.8191]]\n",
      "Init chains per component: [10 10 10 10]\n",
      "Resources or strategies not provided. Using resource strategy bundles.\n",
      "Starting the sampling now . . .\n",
      "Compiling MALA body\n",
      "Compiling training step\n",
      "Compiling training step\n",
      "Compiling NF proposal kernel\n",
      "Updated state target_positions to positions_production\n",
      "Updated state target_log_prob to log_prob_production\n",
      "Updated state target_local_accs to local_accs_production\n",
      "Updated state target_global_accs to global_accs_production\n",
      "Updated state training to False\n",
      "Sampling complete!\n",
      "Saved overlay corner plot to ./runs/gaussian_5d\\results_14\\true_vs_mcmc_corner_plot.pdf\n",
      "Plotting loss curve...\n",
      "Saving loss curve to ./runs/gaussian_5d\\results_14\\training_loss_curve.pdf\n",
      "Loss curve plot saved.\n",
      "Making diagnosis plot . . .\n",
      "Saving diagnosis plots to ./runs/gaussian_5d\\results_14\\acceptance_and_logprob.pdf\n",
      "Making diagnosis plot . . . DONE!\n",
      "KL metrics saved to ./runs/gaussian_5d\\results_14\\kl_metrics.txt\n",
      "MCMC samples saved to ./runs/gaussian_5d\\results_14\\mcmc_samples.json\n",
      "True samples saved to ./runs/gaussian_5d\\results_14\\true_samples.json\n",
      "Sample statistics saved to ./runs/gaussian_5d\\results_14\\sample_statistics.txt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.argv = [\n",
    "    ### The argparse is used to store and process any user input we want to pass on\n",
    "    \"notebook\",                 \n",
    "    \"--experiment-type\", \"gaussian\",\n",
    "    \"--outdir\", \"./runs/gaussian_5d\",\n",
    "\n",
    "    # Everything below here are hyperparameters for the flowMC algorithms.\n",
    "    \"--n-local-steps\", \"40\",\n",
    "    \"--n-global-steps\", \"40\",\n",
    "    \"--n-training-loops\", \"20\",\n",
    "    \"--mala-step-size\", \"1e-1\",\n",
    "    \"--n-production-loops\", \"20\",\n",
    "    \"--n-epochs\", \"10\",\n",
    "    \"--n-chains\", \"40\",\n",
    "    \"--rq-spline-hidden-units\", \"32\",\n",
    "    \"--rq-spline-n-bins\", \"8\",\n",
    "    \"--rq-spline-n-layers\", \"4\",\n",
    "    \"--learning-rate\", \"1e-3\",\n",
    "    \"--batch-size\", \"5000\",\n",
    "    \"--n-max-examples\", \"10000\",\n",
    "    \"--show-initial-positions\", \n",
    "    \n",
    "    # Everything below here are hyperparameters for the gaussians.\n",
    "    \"--nr-of-samples\", \"10000\",\n",
    "    \"--nr-of-components\", \"4\",\n",
    "    \"--n-dims\", \"4\",\n",
    "    \"--width-mean\", \"10.0\",\n",
    "    \"--width-cov\", \"1.0\",\n",
    "    #\"--weights-of-components\", \"0.4\", \"0.3\", \"0.3\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Get the arguments passed over from the command line, and create the experiment runner\n",
    "    args = parser.parse_args()\n",
    "    runner = FlowMCExperimentRunner(args)\n",
    "\n",
    "    # Run the experiment and do some postprocessing\n",
    "    runner.run_experiment()\n",
    "    runner.plot_true_vs_mcmc_corner()\n",
    "    runner.plot_loss_curve()\n",
    "    runner.plot_diagnostics()\n",
    "    runner.kl_metrics()\n",
    "    runner.save_samples_json()\n",
    "    runner.compute_and_save_sample_statistics()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GRASP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
